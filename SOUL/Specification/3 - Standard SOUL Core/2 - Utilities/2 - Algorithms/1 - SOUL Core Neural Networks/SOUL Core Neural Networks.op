SOUL Core Neural Networks

	Philosophy
	
		-
			SOUL core neural networks are three layer neural networks that use gradient input, may
			be dynamically resized, and only train the hidden layer.
		-
	
	Principles
		
		Generation
		
			-
				The neural network will begin with the initial size of the output layer and the
				ratio of the number of neurons between the hidden layer and output layer. All
				connections between the hidden and output layers will be assigned a weight of zero.
				
				The default ratio will be one to one.
			-
			
		Activation Function

			-
				Neurons in the hidden and output layers will use the following activation function:
				
				f(x) = 1 / (1 + e^-x)
			-
		
		Gradient Input
			
			-
				The input vector must be dynamically reset each time the neural network is used.
				
				The weights between the input layer and the hidden layer are determined by the
				following formula, where Ni is the index of the input neuron within the input
				layer, Li is the number of neurons within the input layer, Nh is the index of the
				hidden neuron within the hidden layer, and Lh is the number of neurons within the
				hidden layer:
				
				1 - |((Ni / Li) - (Nh / Lh))|
				
				The index values start at one, unless their corresponding length value is zero, in
				which case their value will be zero.
				
				If either of the length values are zero, then formula will be skipped and the
				weight will be set to zero to avoid a divide by zero error.
			-
		
		Scaling
			
			-
				The ratio of the number of neurons between the hidden layer and the output layer
				must remain constant. Whenever the output layer is resized, any neurons added to
				the hidden layer to keep set ratio constant will be given weights of zero for all
				connections to neurons in the output layer.
			-
		
		Training
			
			-
				The neural network will train only the connections between the hidden and output
				layers, using a number between zero and one as a correlation value. Said number
				will be multiplied by the error of each weight, and the resulting value will be
				what is added to the weight.
			-
		
		String Conversion
			
			-
				The values assigned to the neurons of the input layer and the values returned by
				the output layer can be used to represent characters in a string by multiplying
				said value by 1114112 and flooring the result to get a Unicode character value.
			-